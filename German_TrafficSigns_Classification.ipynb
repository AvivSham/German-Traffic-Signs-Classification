{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "German_TrafficSigns_Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvivSham/German-Traffic-Signs-Classification/blob/master/German_TrafficSigns_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "luLVS-FiONEp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Download the German Traffic Signs Dataset\n",
        "!wget https://d17h27t6h515a5.cloudfront.net/topher/2017/February/5898cd6f_traffic-signs-data/traffic-signs-data.zip\n",
        "!wget https://github.com/AvivSham/German-Traffic-Signs-Classification/blob/master/signnames.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kODZm-nFOQZV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip traffic-signs-data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PtgzFwQjOnXd",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "42eca896-3355-433a-da27-d8d9f8727739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Import dependencies\n",
        "%matplotlib inline\n",
        "import os, pickle, shutil\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import skimage.morphology as morp\n",
        "from skimage.filters import rank\n",
        "from sklearn.utils import shuffle, compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import csv\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Input, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras import optimizers\n",
        "from keras.initializers import random_normal\n",
        "from keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YGxk2yA0jBOx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# constrain seed\n",
        "np.random.seed(seed=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oOYzpzKrYQsM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Moving the data files to directory\n",
        "!mkdir data\n",
        "for i in os.listdir():\n",
        "  if '.p' in i:\n",
        "    shutil.move('./'+i,'./data')\n",
        "\n",
        "try:\n",
        "  shutil.move('./signnames.csv','./data')\n",
        "except:\n",
        "  print('No CSV file was found')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cklYuIJOPOma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Loading Train/Test/Validation data\n",
        "training_file = './data/train.p'\n",
        "validation_file = './data/valid.p'\n",
        "testing_file = './data/test.p'\n",
        "\n",
        "with open (training_file, mode='rb') as f:\n",
        "  train = pickle.load(f)\n",
        "with open (validation_file, mode='rb') as f:\n",
        "  valid = pickle.load(f)\n",
        "with open (testing_file, mode='rb') as f:\n",
        "  test = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kt3SF18vcYrj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Read Sign names/classes\n",
        "signs_classes = []\n",
        "os.chdir('./data')\n",
        "with open ('signnames.csv', 'r') as file:\n",
        "  signnames = csv.reader(file, delimiter = ',')\n",
        "  next(signnames,None)\n",
        "  for row in signnames:\n",
        "    signs_classes.append(row[1])\n",
        "  file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hYc7sbPtgkIf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Data info\n",
        "X_train, Y_train = train['features'], train['labels']\n",
        "X_valid, Y_valid = valid['features'], valid['labels']\n",
        "X_test, Y_test = test['features'], test['labels']\n",
        "n_classes = len(np.unique(Y_train))\n",
        "\n",
        "print(\"Number of train samples: \", X_train.shape[0])\n",
        "print(\"Number of validation samples: \", X_valid.shape[0])\n",
        "print(\"Number of test samples: \", X_test.shape[0])\n",
        "print(\"Number of classses: \", n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UaPg_PB9h5F6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_images(data,y_data, label=\"\", cmap=None, n_images = 10):\n",
        "  plt.figure(figsize = (n_images*2,n_images*2))\n",
        "  for i in range(n_images):\n",
        "    plt.subplot(1,n_images,i+1)\n",
        "    ind = np.random.randint(0,len(data))\n",
        "    if len(data[ind].shape) == 2:\n",
        "      cmap = 'gray'\n",
        "    \n",
        "    plt.imshow(data[ind],cmap = cmap)\n",
        "    plt.xlabel(signs_classes[y_data[ind]], fontsize = 8)\n",
        "    plt.ylabel(label, fontsize = 8)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d2XKySPSkOcg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Show samples of each group\n",
        "show_images(X_train,Y_train,'Traning examples')\n",
        "show_images(X_test,Y_test,'Testing examples')\n",
        "show_images(X_valid,Y_valid,'Validation examples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CB7AVvUNk5gq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_hist(data, label):\n",
        "  plt.hist(data, bins = n_classes)\n",
        "  plt.xlabel(label)\n",
        "  plt.ylabel('class count')\n",
        "  plt.grid('off')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h4NG5eZdkb6d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Show groups histogram\n",
        "show_hist(Y_train, \"Training examples\")\n",
        "show_hist(Y_test, \"Testing examples\")\n",
        "show_hist(Y_valid, \"Validation examples\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WPsG5QLBmK1p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, Y_train = shuffle(X_train, Y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rSHVAg1yn8Vy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_to_gray(image):\n",
        "  \n",
        "  return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yzh-PaHYoUl2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Convert to gray scale images \n",
        "gray_images = list(map(convert_to_gray,X_train))\n",
        "show_images(gray_images,Y_train)\n",
        "np.shape(gray_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hR8bbhkLojxn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def hist_equalization(image):\n",
        "  kernel = morp.disk(30)\n",
        "  return rank.equalize(image, selem=kernel)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_KZ7eK5tNz_N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def adapt_hist_equalization(image,clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2,2))):\n",
        "  return clahe.apply(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pSVGrFYd39Te",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Perform histogram equalization\n",
        "equalizied_gray_images = list(map(hist_equalization,gray_images))\n",
        "show_images(equalizied_gray_images,Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aJhwhQUY4hGd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def norm_image(data):\n",
        "  \n",
        "  normalized_images = np.array(data,dtype = np.float32)/255\n",
        "  return np.expand_dims(normalized_images, axis=-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KRexAE6t6iJh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(x_data,y_data, n_classes = 43):\n",
        "  gray_images = list(map(convert_to_gray,x_data))\n",
        "  hist_equal_images = list(map(adapt_hist_equalization,gray_images))\n",
        "  norm_images = norm_image(hist_equal_images)\n",
        "  y_data = to_categorical(y_data, n_classes)\n",
        "  return norm_images, y_data "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y4OdfrPpoD6y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ConvBlock(model, pool, n_filters, mu, sigma):\n",
        "  model = Conv2D(n_filters, kernel_size = 2, padding = 'same',\n",
        "                 activation = 'relu', \n",
        "                 kernel_initializer = random_normal(mean = mu,stddev = sigma))(model)\n",
        "  \n",
        "  model = Conv2D(n_filters, kernel_size = 2, padding = 'same',\n",
        "                 activation = 'relu', \n",
        "                 kernel_initializer = random_normal(mean = mu,stddev = sigma))(model)\n",
        "  model = MaxPooling2D(pool_size = 2, strides = 2, padding = 'valid')(model)\n",
        "  model = Dropout(0.5)(model)\n",
        "  return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "64ZkxfXZedu_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def VGG_variation(input_shape,nf=32):\n",
        "  \n",
        "  inputs = x = Input(input_shape)\n",
        "  for i in range(3):\n",
        "    x = ConvBlock(x,pool = True, n_filters = nf * (i+2), mu = 0, sigma = 0.1)  \n",
        "  \n",
        "  x = Flatten()(x)\n",
        "  for _ in range(2):\n",
        "    x = Dense(units = 128, activation = 'relu')(x)\n",
        "  output = Dense(units = 43, activation = 'softmax')(x)\n",
        "  VGG_var_model = Model(inputs = inputs, outputs = output)\n",
        "  opti = optimizers.Adam(0.0001)\n",
        "  VGG_var_model.compile(optimizer = opti, loss = 'categorical_crossentropy',\n",
        "                       metrics = ['accuracy','categorical_crossentropy'])\n",
        "  VGG_var_model.summary()\n",
        "  return VGG_var_model\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IulGx0eAlrF8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class My_Callback(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        print(\"train begins!\")\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        print(\"-\", end='')\n",
        "        flag_val=True\n",
        "        if epoch%5==0:\n",
        "            train_acc = logs.get(\"acc\")\n",
        "            train_loss = logs.get(\"loss\")\n",
        "            try:\n",
        "                val_acc = logs.get(\"val_acc\")\n",
        "                val_loss = logs.get(\"val_loss\")\n",
        "            except:\n",
        "                flag_val=False\n",
        "            if flag_val:\n",
        "                print(\"\\n%d\"%epoch, \"\\ttrain_loss: \", train_loss,\n",
        "                      \"\\tval_loss: \", val_loss, \"\\ttrain_acc:\", train_acc, \n",
        "                      \"\\tval_acc:\", val_acc)\n",
        "            else:\n",
        "                print(\"\\n%d\"%epoch, \"\\ttrain_loss: \",\n",
        "                      train_loss, \"\\ttrain_acc:\", train_acc)    \n",
        "        return\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=10,\n",
        "                              verbose=1, mode='auto', min_lr=1e-12)\n",
        "my_callback = My_Callback()\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"VGG_GermanSigns_classification.h5\", monitor='loss', \n",
        "                             verbose=0, save_best_only=True, save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CBdWYBv635Y1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Preprocess the data\n",
        "X_train_processed, Y_train_cat = preprocess(X_train,Y_train)\n",
        "X_valid_processed, Y_valid_cat = preprocess(X_valid, Y_valid)\n",
        "class_weights = create_class_weights(Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t02FWrAa9QkH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Create a variation of VGG model\n",
        "VGG_model = VGG_variation(X_train_processed.shape[1:])\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "weights = compute_class_weight('balanced',classes = np.unique(Y_train),y = Y_train)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rms1mlOtysSF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Training\n",
        "model_history = VGG_model.fit(X_train_processed, Y_train_cat, batch_size=batch_size, epochs=epochs, \n",
        "                    validation_data=(X_valid_processed,Y_valid_cat),shuffle=True,\n",
        "                    callbacks = [my_callback, reduce_lr, checkpoint],verbose=0,\n",
        "                    class_weight = weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXa4yYfU94HF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Plotting ACC and LOSS of training\n",
        "# Accuracy\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.plot(model_history.history['acc'],'r')\n",
        "plt.grid('off')\n",
        "plt.plot(model_history.history['val_acc'],'g')\n",
        "plt.xticks()\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()\n",
        "# Loss \n",
        "plt.figure(figsize = (8,6))\n",
        "plt.grid('off')\n",
        "plt.plot(model_history.history['loss'],'r')\n",
        "plt.plot(model_history.history['val_loss'],'g')\n",
        "plt.xticks()\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IErQsGxFs3jU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Loading best result weights\n",
        "VGG_model.load_weights(\"VGG_GermanSigns_classification.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "thxBfiKOGP1b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Preprocessing and predicting the test group\n",
        "X_test_processed, Y_test_cat = preprocess(X_test, Y_test)\n",
        "predicted = VGG_model.predict(X_test_processed)\n",
        "Y_pred = np.argmax(predicted, axis = 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1BdAHW7-HpPH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Calculating and presenting the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test_cat,axis=1),Y_pred)\n",
        "plt.figure(figsize = (25,25))\n",
        "sn.set(font_scale=1)\n",
        "sn.heatmap(cm, cmap = 'viridis', annot = True, annot_kws = {'size': 8})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FtUuaz85emmT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Printing the results\n",
        "total_accurate = 0\n",
        "for i in range (cm.shape[0]):\n",
        "  print('The accuracy of class No.{} is: {:.2f}%' .format(i+1,100*cm[i,i]/cm[i].sum()))\n",
        "  total_accurate += cm[i,i]\n",
        "  \n",
        "print('The total accuracy is: {:.2f}%' .format(100*total_accurate/cm.sum()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}